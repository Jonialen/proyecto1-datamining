{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos - INE Guatemala\n",
    "\n",
    "**Estadísticas Vitales: Nacimientos, Defunciones, Matrimonios, Divorcios y Defunciones Fetales**\n",
    "\n",
    "Datos del Instituto Nacional de Estadística (INE) de Guatemala, período 2012-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as sp_stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.export import to_dataframe, list_collections, collection_stats, get_column_labels\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*Creating legend with loc.*')\n",
    "warnings.filterwarnings('ignore', message='.*Tight layout.*')\n",
    "\n",
    "print('Setup completo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción General del Conjunto de Datos\n",
    "\n",
    "### 1.1 Colecciones disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver todas las colecciones y sus estadísticas\n",
    "col_stats = collection_stats()\n",
    "for name, data in col_stats.items():\n",
    "    if name.startswith('_'):\n",
    "        continue\n",
    "    print(f\"{name:25s}: {data['count']:>9,} documentos | {len(data['fields']):>3} campos\")\n",
    "    print(f\"  Campos: {', '.join(data['fields'][:15])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cargar dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Elegir el dataset a analizar\n",
    "# Opciones: 'nacimientos', 'defunciones', 'matrimonios', 'divorcios', 'defunciones_fetales'\n",
    "DATASET = 'nacimientos'  # <-- CAMBIAR AQUÍ\n",
    "\n",
    "df = to_dataframe(DATASET)\n",
    "labels_map = get_column_labels(DATASET)\n",
    "\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "print(f\"Filas: {len(df):,}\")\n",
    "print(f\"Columnas: {len(df.columns)}\")\n",
    "print(f\"Años disponibles: {sorted(df['_year'].dropna().unique().astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de cada variable con su label descriptivo\n",
    "meta_cols = ['_year', '_source_file']\n",
    "analysis_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "var_info = []\n",
    "for col in analysis_cols:\n",
    "    desc = labels_map.get(col, col)\n",
    "    dtype = str(df[col].dtype)\n",
    "    n_unique = df[col].nunique()\n",
    "    n_null = df[col].isnull().sum()\n",
    "    pct_null = round(n_null / len(df) * 100, 1)\n",
    "    var_info.append({\n",
    "        'columna': col,\n",
    "        'descripcion': desc,\n",
    "        'tipo': dtype,\n",
    "        'valores_unicos': n_unique,\n",
    "        'nulos': n_null,\n",
    "        'pct_nulos': pct_null\n",
    "    })\n",
    "\n",
    "var_df = pd.DataFrame(var_info)\n",
    "print(f\"Total variables de análisis: {len(var_df)}\")\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de cada variable con su label descriptivo\n",
    "meta_cols = ['_year', '_source_file']\n",
    "analysis_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "var_info = []\n",
    "for col in analysis_cols:\n",
    "    desc = labels_map.get(col, col)\n",
    "    dtype = str(df[col].dtype)\n",
    "    n_unique = df[col].nunique()\n",
    "    n_null = df[col].isnull().sum()\n",
    "    pct_null = round(n_null / len(df) * 100, 1)\n",
    "    var_info.append({\n",
    "        'columna': col,\n",
    "        'descripcion': desc,\n",
    "        'tipo': dtype,\n",
    "        'valores_unicos': n_unique,\n",
    "        'nulos': n_null,\n",
    "        'pct_nulos': pct_null\n",
    "    })\n",
    "\n",
    "var_df = pd.DataFrame(var_info)\n",
    "print(f\"Total variables de análisis: {len(var_df)}\")\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar variables en numéricas y categóricas\n",
    "# Intentar convertir columnas que parecen numéricas pero están como string\n",
    "for col in analysis_cols:\n",
    "    if df[col].dtype == 'object' or str(df[col].dtype).startswith('str'):\n",
    "        try:\n",
    "            converted = pd.to_numeric(df[col], errors='coerce')\n",
    "            if converted.notna().sum() / df[col].notna().sum() > 0.8:\n",
    "                df[col] = converted\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "num_cols = df[analysis_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in analysis_cols if c not in num_cols]\n",
    "\n",
    "def label(col, max_len=40):\n",
    "    \"\"\"Retorna el label descriptivo, truncado y sin notas.\"\"\"\n",
    "    raw = labels_map.get(col, col)\n",
    "    if 'Nota:' in raw:\n",
    "        raw = raw.split('Nota:')[0].strip()\n",
    "    if len(raw) > max_len:\n",
    "        raw = raw[:max_len-3] + '...'\n",
    "    return raw\n",
    "\n",
    "print(f\"Variables numéricas ({len(num_cols)}):\")\n",
    "for c in num_cols:\n",
    "    print(f\"  {c:15s} -> {label(c)}\")\n",
    "\n",
    "print(f\"\\nVariables categóricas ({len(cat_cols)}):\")\n",
    "for c in cat_cols:\n",
    "    print(f\"  {c:15s} -> {label(c)} ({df[c].nunique()} cat.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración de Variables Numéricas\n",
    "\n",
    "### 2.1 Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir variables que son solo identificadores (año de registro, año de ocurrencia)\n",
    "id_cols = [c for c in num_cols if 'reg' in c or (df[c].dropna().between(2000, 2030).mean() > 0.9)]\n",
    "meaningful_num = [c for c in num_cols if c not in id_cols]\n",
    "\n",
    "print(f\"Variables numéricas de análisis (excluyendo años/IDs): {len(meaningful_num)}\")\n",
    "for c in meaningful_num:\n",
    "    print(f\"  {c}: {label(c)}\")\n",
    "\n",
    "if id_cols:\n",
    "    print(f\"\\nExcluidas (años/IDs): {[f'{c} ({label(c)})' for c in id_cols]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas de tendencia central, dispersión y orden\n",
    "if meaningful_num:\n",
    "    desc = df[meaningful_num].describe().T\n",
    "    desc['mediana'] = df[meaningful_num].median()\n",
    "    desc['moda'] = df[meaningful_num].mode().iloc[0] if len(df[meaningful_num].mode()) > 0 else None\n",
    "    desc['asimetria'] = df[meaningful_num].skew()\n",
    "    desc['curtosis'] = df[meaningful_num].kurtosis()\n",
    "    desc['cv_%'] = (desc['std'] / desc['mean'] * 100).round(2)\n",
    "    desc['riq'] = desc['75%'] - desc['25%']\n",
    "    desc.index = [f\"{c} ({label(c)})\" for c in desc.index]\n",
    "    desc\n",
    "else:\n",
    "    print(\"No hay variables numéricas significativas (las existentes son solo años/IDs)\")\n",
    "    print(\"Esto es normal para este dataset donde la mayoría de variables son categóricas.\")\n",
    "    desc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de variables numéricas significativas\n",
    "plot_num = [c for c in meaningful_num if df[c].nunique() > 2]\n",
    "\n",
    "if plot_num:\n",
    "    n = len(plot_num)\n",
    "    ncols_plot = min(3, n)\n",
    "    nrows_plot = (n + ncols_plot - 1) // ncols_plot\n",
    "    fig, axes = plt.subplots(nrows_plot, ncols_plot, figsize=(5*ncols_plot, 4*nrows_plot))\n",
    "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "\n",
    "    for i, col in enumerate(plot_num):\n",
    "        ax = axes[i]\n",
    "        data = df[col].dropna()\n",
    "        ax.hist(data, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "        ax.set_title(label(col), fontsize=11)\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frecuencia')\n",
    "\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.suptitle('Distribución de Variables Numéricas', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay variables numéricas significativas para graficar histogramas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_num:\n",
    "    n = len(plot_num)\n",
    "    ncols_plot = min(3, n)\n",
    "    nrows_plot = (n + ncols_plot - 1) // ncols_plot\n",
    "    fig, axes = plt.subplots(nrows_plot, ncols_plot, figsize=(5*ncols_plot, 4*nrows_plot))\n",
    "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "\n",
    "    for i, col in enumerate(plot_num):\n",
    "        ax = axes[i]\n",
    "        data = df[col].dropna()\n",
    "        ax.boxplot(data, vert=True)\n",
    "        ax.set_title(label(col), fontsize=11)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.suptitle('Boxplots de Variables Numéricas', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay variables numéricas significativas para graficar boxplots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Test de normalidad (Shapiro-Wilk)\n",
    "\n",
    "Se usa una muestra de 5000 observaciones (límite de Shapiro-Wilk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalidad para variables numéricas significativas\n",
    "normality_results = []\n",
    "sample_size = 5000\n",
    "\n",
    "test_cols = meaningful_num if meaningful_num else num_cols\n",
    "\n",
    "for col in test_cols:\n",
    "    data = df[col].dropna()\n",
    "    if len(data) < 3:\n",
    "        continue\n",
    "    sample = data.sample(min(sample_size, len(data)), random_state=42)\n",
    "    stat, p_value = sp_stats.shapiro(sample)\n",
    "    normality_results.append({\n",
    "        'variable': col,\n",
    "        'descripcion': label(col),\n",
    "        'statistic': round(stat, 4),\n",
    "        'p_value': f\"{p_value:.2e}\",\n",
    "        'normal (α=0.05)': 'Sí' if p_value > 0.05 else 'No',\n",
    "        'asimetria': round(data.skew(), 3),\n",
    "    })\n",
    "\n",
    "norm_df = pd.DataFrame(normality_results)\n",
    "if len(norm_df) > 0:\n",
    "    print(\"Resultados del test de Shapiro-Wilk:\")\n",
    "    display(norm_df)\n",
    "else:\n",
    "    print(\"No hay suficientes variables numéricas para el test de normalidad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploración de Variables Categóricas\n",
    "\n",
    "### 3.1 Tablas de frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tablas de frecuencia para variables categóricas principales\n",
    "# Excluir municipios y variables con demasiadas categorías (>50)\n",
    "main_cat_cols = [c for c in cat_cols if df[c].nunique() <= 50 and df[c].notna().sum() > len(df) * 0.1]\n",
    "\n",
    "for col in main_cat_cols:\n",
    "    desc_label = label(col)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{col} - {desc_label} ({df[col].nunique()} categorías)\")\n",
    "    print('='*60)\n",
    "\n",
    "    freq = df[col].value_counts()\n",
    "    prop = df[col].value_counts(normalize=True) * 100\n",
    "\n",
    "    table = pd.DataFrame({\n",
    "        'frecuencia': freq,\n",
    "        'porcentaje': prop.round(2),\n",
    "        'acumulado_%': prop.cumsum().round(2)\n",
    "    })\n",
    "\n",
    "    if len(table) > 20:\n",
    "        print(table.head(20))\n",
    "        print(f\"  ... y {len(table) - 20} categorías más\")\n",
    "    else:\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gráficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de barras para variables categóricas con pocas categorías\n",
    "bar_cols = [c for c in main_cat_cols if 2 <= df[c].nunique() <= 25]\n",
    "\n",
    "for col in bar_cols[:10]:  # Máximo 10 gráficos\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, df[col].nunique() * 0.4)))\n",
    "    freq = df[col].value_counts().head(20)\n",
    "\n",
    "    colors = sns.color_palette('viridis', len(freq))\n",
    "    freq.plot(kind='barh', ax=ax, color=colors)\n",
    "    ax.set_title(f\"{label(col)} ({col})\", fontsize=13)\n",
    "    ax.set_xlabel('Frecuencia')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    # Agregar porcentajes\n",
    "    total = freq.sum()\n",
    "    for i, (val, count) in enumerate(freq.items()):\n",
    "        ax.text(count + total*0.005, i, f\" {count/total*100:.1f}%\", va='center', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Relaciones entre Variables\n",
    "\n",
    "### 4.1 Matriz de correlación (variables numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación con todas las numéricas\n",
    "corr_cols = [c for c in num_cols if df[c].nunique() > 2]\n",
    "\n",
    "if len(corr_cols) >= 2:\n",
    "    corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "    # Labels cortos para el heatmap\n",
    "    corr_labels = {c: label(c, max_len=25) for c in corr_cols}\n",
    "    corr_display = corr_matrix.rename(index=corr_labels, columns=corr_labels)\n",
    "\n",
    "    size = max(8, len(corr_cols) * 2.5)\n",
    "    fig, ax = plt.subplots(figsize=(size, size * 0.8))\n",
    "    mask = np.triu(np.ones_like(corr_display, dtype=bool))\n",
    "    sns.heatmap(corr_display, mask=mask, annot=True, fmt='.2f',\n",
    "                cmap='coolwarm', center=0, ax=ax, vmin=-1, vmax=1,\n",
    "                annot_kws={'size': 10})\n",
    "    ax.set_title('Matriz de Correlación', fontsize=14)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax.tick_params(axis='y', rotation=0, labelsize=9)\n",
    "    plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    # Top correlaciones\n",
    "    pairs = []\n",
    "    for i in range(len(corr_cols)):\n",
    "        for j in range(i+1, len(corr_cols)):\n",
    "            pairs.append({\n",
    "                'var1': f\"{corr_cols[i]} ({label(corr_cols[i])})\",\n",
    "                'var2': f\"{corr_cols[j]} ({label(corr_cols[j])})\",\n",
    "                'correlacion': round(corr_matrix.iloc[i, j], 4)\n",
    "            })\n",
    "    pairs_df = pd.DataFrame(pairs).sort_values('correlacion', key=abs, ascending=False)\n",
    "    print(\"\\nCorrelaciones ordenadas por magnitud:\")\n",
    "    display(pairs_df)\n",
    "else:\n",
    "    print(\"No hay suficientes variables numéricas para la matriz de correlación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots entre pares de variables numéricas significativas\n",
    "scatter_cols = meaningful_num if len(meaningful_num) >= 2 else corr_cols\n",
    "\n",
    "if len(scatter_cols) >= 2:\n",
    "    from itertools import combinations\n",
    "    pairs = list(combinations(scatter_cols, 2))[:6]  # Max 6 scatter plots\n",
    "\n",
    "    n = len(pairs)\n",
    "    ncols_plot = min(3, n)\n",
    "    nrows_plot = (n + ncols_plot - 1) // ncols_plot\n",
    "    fig, axes = plt.subplots(nrows_plot, ncols_plot, figsize=(5*ncols_plot, 5*nrows_plot))\n",
    "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "\n",
    "    sample = df.sample(min(5000, len(df)), random_state=42)\n",
    "    for i, (c1, c2) in enumerate(pairs):\n",
    "        axes[i].scatter(sample[c1], sample[c2], alpha=0.3, s=10, color='steelblue')\n",
    "        axes[i].set_xlabel(label(c1))\n",
    "        axes[i].set_ylabel(label(c2))\n",
    "        r = df[[c1, c2]].dropna().corr().iloc[0, 1]\n",
    "        axes[i].set_title(f'{label(c1)} vs {label(c2)}\\n(r={r:.3f})', fontsize=10)\n",
    "\n",
    "    for j in range(len(pairs), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay suficientes variables numéricas para scatter plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tablas cruzadas (Crosstabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstabs entre variables categóricas con pocas categorías\n",
    "cross_candidates = [c for c in cat_cols if 2 <= df[c].nunique() <= 10 and df[c].notna().sum() > len(df) * 0.5]\n",
    "\n",
    "if len(cross_candidates) >= 2:\n",
    "    from itertools import combinations\n",
    "    cross_pairs = list(combinations(cross_candidates[:6], 2))[:4]  # Top 4 cruces\n",
    "\n",
    "    for c1, c2 in cross_pairs:\n",
    "        ct = pd.crosstab(df[c1], df[c2])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(max(8, ct.shape[1]*1.5), max(5, ct.shape[0]*0.6)))\n",
    "        sns.heatmap(ct, annot=True, fmt=',d', cmap='YlOrRd', ax=ax)\n",
    "        ax.set_title(f'{label(c1)} vs {label(c2)}', fontsize=13)\n",
    "        ax.set_xlabel(label(c2))\n",
    "        ax.set_ylabel(label(c1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No hay suficientes variables categóricas con pocas categorías para crosstabs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros por año\n",
    "yearly = df.groupby('_year').size().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(yearly.index.astype(int).astype(str), yearly.values,\n",
    "              color='steelblue', edgecolor='black')\n",
    "ax.set_title(f'Registros de {DATASET} por año', fontsize=14)\n",
    "ax.set_xlabel('Año')\n",
    "ax.set_ylabel('Cantidad de registros')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Mostrar valores encima de las barras\n",
    "for bar, val in zip(bars, yearly.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + yearly.max()*0.01,\n",
    "            f'{val:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por mes de ocurrencia (si existe)\n",
    "mes_col = None\n",
    "for c in cat_cols:\n",
    "    if 'mesocu' in c:\n",
    "        mes_col = c\n",
    "        break\n",
    "\n",
    "if mes_col:\n",
    "    monthly = df[mes_col].value_counts().sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    monthly.plot(kind='bar', ax=ax, color='darkorange', edgecolor='black')\n",
    "    ax.set_title(f'{label(mes_col)} - Distribución mensual', fontsize=14)\n",
    "    ax.set_xlabel('Mes')\n",
    "    ax.set_ylabel('Frecuencia')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Datos atípicos (Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers con IQR para variables numéricas significativas\n",
    "outlier_cols = meaningful_num if meaningful_num else [c for c in num_cols if df[c].nunique() > 5]\n",
    "\n",
    "if outlier_cols:\n",
    "    outlier_report = []\n",
    "    for col in outlier_cols:\n",
    "        data = df[col].dropna()\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        if IQR == 0:\n",
    "            continue\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        n_outliers = ((data < lower) | (data > upper)).sum()\n",
    "        outlier_report.append({\n",
    "            'variable': col,\n",
    "            'descripcion': label(col),\n",
    "            'Q1': Q1,\n",
    "            'Q3': Q3,\n",
    "            'IQR': IQR,\n",
    "            'limite_inf': lower,\n",
    "            'limite_sup': upper,\n",
    "            'n_outliers': n_outliers,\n",
    "            'pct_outliers': round(n_outliers / len(data) * 100, 2),\n",
    "        })\n",
    "\n",
    "    if outlier_report:\n",
    "        outlier_df = pd.DataFrame(outlier_report)\n",
    "        display(outlier_df)\n",
    "    else:\n",
    "        print(\"No se detectaron outliers con el método IQR.\")\n",
    "else:\n",
    "    print(\"No hay variables numéricas significativas para análisis de outliers.\")\n",
    "    print(\"Las variables numéricas existentes son años e IDs, que no aplican.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clustering\n",
    "\n",
    "### 7.1 Preparación de datos\n",
    "\n",
    "Para clustering usamos tanto variables numéricas como categóricas codificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variables para clustering\n",
    "# Excluir: municipios, meses (dominan el one-hot y crean clusters por mes),\n",
    "# departamentos, y variables con >92% nulos\n",
    "exclude_cluster = {'mesreg', 'mesocu', 'depreg', 'depocu', 'dredif', 'dnadif'}\n",
    "cluster_cat = [c for c in cat_cols\n",
    "               if 2 <= df[c].nunique() <= 15\n",
    "               and df[c].notna().sum() > len(df) * 0.7\n",
    "               and c not in exclude_cluster\n",
    "               and 'mun' not in c and 'mup' not in c]\n",
    "\n",
    "cluster_num = [c for c in meaningful_num if df[c].notna().sum() > len(df) * 0.7]\n",
    "\n",
    "print(f\"Variables para clustering:\")\n",
    "print(f\"  Numéricas ({len(cluster_num)}):\")\n",
    "for c in cluster_num:\n",
    "    print(f\"    - {c}: {label(c)}\")\n",
    "print(f\"  Categóricas ({len(cluster_cat)}, se codificarán con one-hot):\")\n",
    "for c in cluster_cat:\n",
    "    print(f\"    - {c}: {label(c)} ({df[c].nunique()} cat.)\")\n",
    "\n",
    "# Preparar DataFrame\n",
    "df_clust = df[cluster_num + cluster_cat].dropna().copy()\n",
    "\n",
    "# One-hot encode\n",
    "if cluster_cat:\n",
    "    df_encoded = pd.get_dummies(df_clust, columns=cluster_cat, drop_first=False)\n",
    "else:\n",
    "    df_encoded = df_clust.copy()\n",
    "\n",
    "# Estandarizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# Muestra si es muy grande\n",
    "if len(X_scaled) > 50000:\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(len(X_scaled), 50000, replace=False)\n",
    "    X_sample = X_scaled[idx]\n",
    "else:\n",
    "    X_sample = X_scaled\n",
    "\n",
    "print(f\"\\nDatos: {X_sample.shape[0]:,} filas x {X_sample.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Método del codo y silueta para determinar K óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_range = range(2, 9)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "sil_sample = X_sample[:10000] if len(X_sample) > 10000 else X_sample\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km_labels = kmeans.fit_predict(X_sample)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "    sil_labels = kmeans.predict(sil_sample)\n",
    "    sil = silhouette_score(sil_sample, sil_labels)\n",
    "    silhouettes.append(sil)\n",
    "    print(f\"  K={k}: inercia={kmeans.inertia_:,.0f}, silueta={sil:.4f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "ax1.set_xlabel('Número de clusters (K)')\n",
    "ax1.set_ylabel('Inercia')\n",
    "ax1.set_title('Método del Codo')\n",
    "\n",
    "ax2.plot(K_range, silhouettes, 'ro-', linewidth=2)\n",
    "ax2.set_xlabel('Número de clusters (K)')\n",
    "ax2.set_ylabel('Coeficiente de Silueta')\n",
    "ax2.set_title('Método de la Silueta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = list(K_range)[np.argmax(silhouettes)]\n",
    "print(f\"\\nMejor K según silueta: {best_k} (score: {max(silhouettes):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Clustering final e interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering con K óptimo\n",
    "kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled[:len(df_clust)])\n",
    "df_clust['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Distribución de clusters (K={best_k}):\")\n",
    "cluster_dist = df_clust['cluster'].value_counts().sort_index()\n",
    "for cl, count in cluster_dist.items():\n",
    "    print(f\"  Cluster {cl}: {count:>9,} ({count/len(df_clust)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar clusters con PCA (muestra para rendimiento)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled[:len(df_clust)])\n",
    "\n",
    "plot_n = min(20000, len(X_pca))\n",
    "np.random.seed(42)\n",
    "plot_idx = np.random.choice(len(X_pca), plot_n, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for cl in range(best_k):\n",
    "    mask = cluster_labels[plot_idx] == cl\n",
    "    ax.scatter(X_pca[plot_idx[mask], 0], X_pca[plot_idx[mask], 1],\n",
    "              alpha=0.4, s=8, label=f'Cluster {cl}')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza explicada)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza explicada)')\n",
    "ax.set_title(f'Clusters (K={best_k}) - Proyección PCA', fontsize=14)\n",
    "ax.legend(loc='upper right', markerscale=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretar clusters: perfil de cada cluster con variables categóricas\n",
    "print(\"=== Perfil de cada cluster ===\")\n",
    "for cat_col in cluster_cat:\n",
    "    print(f\"\\n--- {label(cat_col)} ({cat_col}) ---\")\n",
    "    ct = pd.crosstab(df_clust['cluster'], df_clust[cat_col], normalize='index') * 100\n",
    "    print(ct.round(1).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil numérico por cluster\n",
    "if cluster_num:\n",
    "    print(\"=== Medias de variables numéricas por cluster ===\")\n",
    "    cluster_means = df_clust.groupby('cluster')[cluster_num].mean()\n",
    "    cluster_means.columns = [f\"{c} ({label(c)})\" for c in cluster_means.columns]\n",
    "    display(cluster_means.round(2))\n",
    "\n",
    "    # Boxplots por cluster\n",
    "    n = len(cluster_num)\n",
    "    if n > 0:\n",
    "        ncols_plot = min(3, n)\n",
    "        nrows_plot = (n + ncols_plot - 1) // ncols_plot\n",
    "        fig, axes = plt.subplots(nrows_plot, ncols_plot, figsize=(5*ncols_plot, 4*nrows_plot))\n",
    "        axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "\n",
    "        for i, col in enumerate(cluster_num):\n",
    "            df_clust.boxplot(column=col, by='cluster', ax=axes[i])\n",
    "            axes[i].set_title(label(col))\n",
    "            axes[i].set_xlabel('Cluster')\n",
    "\n",
    "        for j in range(n, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "\n",
    "        plt.suptitle('Variables numéricas por cluster', fontsize=14, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
